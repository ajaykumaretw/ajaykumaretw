{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'source': 'gutenberg', 'id': '3urfvvm165iantk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version                                               data\n",
       "0        1  {'source': 'wikipedia', 'id': '3zotghdk5ibi9ce...\n",
       "1        1  {'source': 'cnn', 'id': '3wj1oxy92agboo5nlq4r7...\n",
       "2        1  {'source': 'gutenberg', 'id': '3bdcf01ogxu7zdn...\n",
       "3        1  {'source': 'cnn', 'id': '3ewijtffvo7wwchw6rtya...\n",
       "4        1  {'source': 'gutenberg', 'id': '3urfvvm165iantk..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coqa = pd.read_json('G:/ajaykumaretw/QuestionAnswerUsingNPLBert/coqa-train-v1.0.json')\n",
    "coqa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del coqa[\"version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every question-answer pair, we will be attaching the linked story to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required columns in our dataframe\n",
    "cols = [\"text\",\"question\",\"answer\"]\n",
    "#list of lists to create our dataframe\n",
    "comp_list = []\n",
    "for index, row in coqa.iterrows():\n",
    "    for i in range(len(row[\"data\"][\"questions\"])):\n",
    "        temp_list = []\n",
    "        temp_list.append(row[\"data\"][\"story\"])\n",
    "        temp_list.append(row[\"data\"][\"questions\"][i][\"input_text\"])\n",
    "        temp_list.append(row[\"data\"][\"answers\"][i][\"input_text\"])\n",
    "        comp_list.append(temp_list)\n",
    "new_df = pd.DataFrame(comp_list, columns=cols) \n",
    "#saving the dataframe to csv file for further loading\n",
    "new_df.to_csv(\"CoQA_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading from Local CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>When was the Vat formally opened?</td>\n",
       "      <td>It was formally established in 1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what is the library for?</td>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>for what subjects?</td>\n",
       "      <td>history, and law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>and?</td>\n",
       "      <td>philosophy, science and theology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Vatican Apostolic Library (), more commonl...</td>\n",
       "      <td>what was started in 2014?</td>\n",
       "      <td>a  project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The Vatican Apostolic Library (), more commonl...   \n",
       "1  The Vatican Apostolic Library (), more commonl...   \n",
       "2  The Vatican Apostolic Library (), more commonl...   \n",
       "3  The Vatican Apostolic Library (), more commonl...   \n",
       "4  The Vatican Apostolic Library (), more commonl...   \n",
       "\n",
       "                            question                               answer  \n",
       "0  When was the Vat formally opened?  It was formally established in 1475  \n",
       "1           what is the library for?                             research  \n",
       "2                 for what subjects?                     history, and law  \n",
       "3                               and?     philosophy, science and theology  \n",
       "4          what was started in 2014?                           a  project  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"CoQA_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question and answers:  108647\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of question and answers: \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best part about using these pre-trained models is that you can load the model and its tokenizer in just two simple lines of code. ðŸ˜² Isnâ€™t it simply wow? For tasks like text classification, we need to fine-tune BERT on our dataset. But for question answering tasks, we can even use the already trained model and get decent results even when our text is from a completely different domain. To get decent results, we are using a BERT model which is fine-tuned on the SQuAD benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking a Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,len(data))\n",
    "question = data[\"question\"][random_num]\n",
    "text = data[\"text\"][random_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where did she pass?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEW YORK (CNN) -- After spending nearly 28 years in an irreversible coma, heiress and socialite Martha \"Sunny\" von Bulow died Saturday in a New York nursing home, according to a family statement. She was 76. \\n\\nSunny von Bulow is pictured during her 1957 wedding to Prince Alfred von Auersperg. \\n\\nVon Bulow was subject of one of the nation\\'s most sensational criminal cases during the 1980s. \\n\\nHer husband, Claus, was accused of trying to kill her with an overdose of insulin, which prosecutors alleged sent her into the coma. \\n\\nHe was convicted of making two attempts on her life, but the conviction was overturned on appeal. He was acquitted in a second trial. \\n\\nHis retrial in 1985 received national attention. \\n\\n\"We were blessed to have an extraordinarily loving and caring mother,\" said the statement from Von Bulow\\'s three children -- Annie Laurie \"Ala\" Isham, Alexander von Auersperg and Cosima Pavoncelli -- released by a spokeswoman. \"She was especially devoted to her many friends and family members.\" \\n\\nMartha von Bulow was born Martha Sharp Crawford into a wealthy family. She inherited a fortune conservatively estimated at $75 million, according to an article on the von Bulow case posted on truTV.com\\'s Crime Library Web site. \\n\\nIn her early years, she drew comparisons to actress Grace Kelly. \\n\\nShe became known as Princess von Auersperg with her first marriage, to Prince Alfred von Auersperg of Austria. That marriage produced two children: Alexander and Annie Laurie. \\n\\nThe von Bulows married in 1966 and had a daughter, Cosima. '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s tokenize the question and text as a pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input has a total of 354 tokens.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(question, text)\n",
    "print(\"The input has a total of {} tokens.\".format(len(input_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at what our tokenizer is doing, letâ€™s just print out the tokens and their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]        101\n",
      "where      2,073\n",
      "did        2,106\n",
      "she        2,016\n",
      "pass       3,413\n",
      "?          1,029\n",
      "[SEP]        102\n",
      "new        2,047\n",
      "york       2,259\n",
      "(          1,006\n",
      "cnn       13,229\n",
      ")          1,007\n",
      "-          1,011\n",
      "-          1,011\n",
      "after      2,044\n",
      "spending   5,938\n",
      "nearly     3,053\n",
      "28         2,654\n",
      "years      2,086\n",
      "in         1,999\n",
      "an         2,019\n",
      "ir        20,868\n",
      "##re       2,890\n",
      "##vers    14,028\n",
      "##ible     7,028\n",
      "coma      16,571\n",
      ",          1,010\n",
      "heiress   20,020\n",
      "and        1,998\n",
      "social     2,591\n",
      "##ite      4,221\n",
      "martha     9,246\n",
      "\"          1,000\n",
      "sunny     11,559\n",
      "\"          1,000\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "died       2,351\n",
      "saturday   5,095\n",
      "in         1,999\n",
      "a          1,037\n",
      "new        2,047\n",
      "york       2,259\n",
      "nursing    8,329\n",
      "home       2,188\n",
      ",          1,010\n",
      "according   2,429\n",
      "to         2,000\n",
      "a          1,037\n",
      "family     2,155\n",
      "statement   4,861\n",
      ".          1,012\n",
      "she        2,016\n",
      "was        2,001\n",
      "76         6,146\n",
      ".          1,012\n",
      "sunny     11,559\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "is         2,003\n",
      "pictured  15,885\n",
      "during     2,076\n",
      "her        2,014\n",
      "1957       3,890\n",
      "wedding    5,030\n",
      "to         2,000\n",
      "prince     3,159\n",
      "alfred     6,152\n",
      "von        3,854\n",
      "au         8,740\n",
      "##ers      2,545\n",
      "##per      4,842\n",
      "##g        2,290\n",
      ".          1,012\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "was        2,001\n",
      "subject    3,395\n",
      "of         1,997\n",
      "one        2,028\n",
      "of         1,997\n",
      "the        1,996\n",
      "nation     3,842\n",
      "'          1,005\n",
      "s          1,055\n",
      "most       2,087\n",
      "sensation   8,742\n",
      "##al       2,389\n",
      "criminal   4,735\n",
      "cases      3,572\n",
      "during     2,076\n",
      "the        1,996\n",
      "1980s      3,865\n",
      ".          1,012\n",
      "her        2,014\n",
      "husband    3,129\n",
      ",          1,010\n",
      "claus     19,118\n",
      ",          1,010\n",
      "was        2,001\n",
      "accused    5,496\n",
      "of         1,997\n",
      "trying     2,667\n",
      "to         2,000\n",
      "kill       3,102\n",
      "her        2,014\n",
      "with       2,007\n",
      "an         2,019\n",
      "overdose  26,641\n",
      "of         1,997\n",
      "insulin   22,597\n",
      ",          1,010\n",
      "which      2,029\n",
      "prosecutors  19,608\n",
      "alleged    6,884\n",
      "sent       2,741\n",
      "her        2,014\n",
      "into       2,046\n",
      "the        1,996\n",
      "coma      16,571\n",
      ".          1,012\n",
      "he         2,002\n",
      "was        2,001\n",
      "convicted   7,979\n",
      "of         1,997\n",
      "making     2,437\n",
      "two        2,048\n",
      "attempts   4,740\n",
      "on         2,006\n",
      "her        2,014\n",
      "life       2,166\n",
      ",          1,010\n",
      "but        2,021\n",
      "the        1,996\n",
      "conviction  10,652\n",
      "was        2,001\n",
      "overturned  17,068\n",
      "on         2,006\n",
      "appeal     5,574\n",
      ".          1,012\n",
      "he         2,002\n",
      "was        2,001\n",
      "acquitted  18,538\n",
      "in         1,999\n",
      "a          1,037\n",
      "second     2,117\n",
      "trial      3,979\n",
      ".          1,012\n",
      "his        2,010\n",
      "re         2,128\n",
      "##tri     18,886\n",
      "##al       2,389\n",
      "in         1,999\n",
      "1985       3,106\n",
      "received   2,363\n",
      "national   2,120\n",
      "attention   3,086\n",
      ".          1,012\n",
      "\"          1,000\n",
      "we         2,057\n",
      "were       2,020\n",
      "blessed   10,190\n",
      "to         2,000\n",
      "have       2,031\n",
      "an         2,019\n",
      "extra      4,469\n",
      "##ord      8,551\n",
      "##ina      3,981\n",
      "##rily    11,272\n",
      "loving     8,295\n",
      "and        1,998\n",
      "caring    11,922\n",
      "mother     2,388\n",
      ",          1,010\n",
      "\"          1,000\n",
      "said       2,056\n",
      "the        1,996\n",
      "statement   4,861\n",
      "from       2,013\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "'          1,005\n",
      "s          1,055\n",
      "three      2,093\n",
      "children   2,336\n",
      "-          1,011\n",
      "-          1,011\n",
      "annie      8,194\n",
      "laurie    16,450\n",
      "\"          1,000\n",
      "ala       21,862\n",
      "\"          1,000\n",
      "is         2,003\n",
      "##ham      3,511\n",
      ",          1,010\n",
      "alexander   3,656\n",
      "von        3,854\n",
      "au         8,740\n",
      "##ers      2,545\n",
      "##per      4,842\n",
      "##g        2,290\n",
      "and        1,998\n",
      "co         2,522\n",
      "##si       5,332\n",
      "##ma       2,863\n",
      "pa         6,643\n",
      "##von     17,789\n",
      "##cel     29,109\n",
      "##li       3,669\n",
      "-          1,011\n",
      "-          1,011\n",
      "released   2,207\n",
      "by         2,011\n",
      "a          1,037\n",
      "spoke      3,764\n",
      "##sw      26,760\n",
      "##oman    20,778\n",
      ".          1,012\n",
      "\"          1,000\n",
      "she        2,016\n",
      "was        2,001\n",
      "especially   2,926\n",
      "devoted    7,422\n",
      "to         2,000\n",
      "her        2,014\n",
      "many       2,116\n",
      "friends    2,814\n",
      "and        1,998\n",
      "family     2,155\n",
      "members    2,372\n",
      ".          1,012\n",
      "\"          1,000\n",
      "martha     9,246\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "was        2,001\n",
      "born       2,141\n",
      "martha     9,246\n",
      "sharp      4,629\n",
      "crawford  10,554\n",
      "into       2,046\n",
      "a          1,037\n",
      "wealthy    7,272\n",
      "family     2,155\n",
      ".          1,012\n",
      "she        2,016\n",
      "inherited   7,900\n",
      "a          1,037\n",
      "fortune    7,280\n",
      "conservative   4,603\n",
      "##ly       2,135\n",
      "estimated   4,358\n",
      "at         2,012\n",
      "$          1,002\n",
      "75         4,293\n",
      "million    2,454\n",
      ",          1,010\n",
      "according   2,429\n",
      "to         2,000\n",
      "an         2,019\n",
      "article    3,720\n",
      "on         2,006\n",
      "the        1,996\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "case       2,553\n",
      "posted     6,866\n",
      "on         2,006\n",
      "tr        19,817\n",
      "##ut       4,904\n",
      "##v        2,615\n",
      ".          1,012\n",
      "com        4,012\n",
      "'          1,005\n",
      "s          1,055\n",
      "crime      4,126\n",
      "library    3,075\n",
      "web        4,773\n",
      "site       2,609\n",
      ".          1,012\n",
      "in         1,999\n",
      "her        2,014\n",
      "early      2,220\n",
      "years      2,086\n",
      ",          1,010\n",
      "she        2,016\n",
      "drew       3,881\n",
      "comparisons  18,539\n",
      "to         2,000\n",
      "actress    3,883\n",
      "grace      4,519\n",
      "kelly      5,163\n",
      ".          1,012\n",
      "she        2,016\n",
      "became     2,150\n",
      "known      2,124\n",
      "as         2,004\n",
      "princess   4,615\n",
      "von        3,854\n",
      "au         8,740\n",
      "##ers      2,545\n",
      "##per      4,842\n",
      "##g        2,290\n",
      "with       2,007\n",
      "her        2,014\n",
      "first      2,034\n",
      "marriage   3,510\n",
      ",          1,010\n",
      "to         2,000\n",
      "prince     3,159\n",
      "alfred     6,152\n",
      "von        3,854\n",
      "au         8,740\n",
      "##ers      2,545\n",
      "##per      4,842\n",
      "##g        2,290\n",
      "of         1,997\n",
      "austria    5,118\n",
      ".          1,012\n",
      "that       2,008\n",
      "marriage   3,510\n",
      "produced   2,550\n",
      "two        2,048\n",
      "children   2,336\n",
      ":          1,024\n",
      "alexander   3,656\n",
      "and        1,998\n",
      "annie      8,194\n",
      "laurie    16,450\n",
      ".          1,012\n",
      "the        1,996\n",
      "von        3,854\n",
      "bu        20,934\n",
      "##low      8,261\n",
      "##s        2,015\n",
      "married    2,496\n",
      "in         1,999\n",
      "1966       3,547\n",
      "and        1,998\n",
      "had        2,018\n",
      "a          1,037\n",
      "daughter   2,684\n",
      ",          1,010\n",
      "co         2,522\n",
      "##si       5,332\n",
      "##ma       2,863\n",
      ".          1,012\n",
      "[SEP]        102\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "for token, id in zip(tokens, input_ids):\n",
    "    print('{:8}{:8,}'.format(token,id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-BERT has a unique way of processing the tokenized inputs.\n",
    "****We can see two special tokens [CLS] and [SEP].\n",
    " -[CLS] token stands for classification -To represent sentence-level classification and is used when we are classifying.\n",
    " -[SEP] to separate the two pieces of text\n",
    "\n",
    " Here Two [SEP] tokens in the above, one after the question and another after the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the \"Token Embeddings\", BERT internally also uses \"Segment Embeddings\" and \"Position Embeddings\". Segment embeddings help BERT in differentiating a question from the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice-\n",
    "\n",
    "we use a vector of 0's if embeddings are from sentence 1 else a vector of 1â€™s if embeddings are from sentence 2. \n",
    "\n",
    "Position embeddings help in specifying the position of words in the sequence. All these embeddings are fed to the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers library can create segment embeddings on its own using PretrainedTokenizer.encode_plus(). But, we can even create our own. For that, we just need to specify a 0 or 1 for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEP token index:  6\n"
     ]
    }
   ],
   "source": [
    "#first occurence of [SEP] token\n",
    "sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "print(\"SEP token index: \", sep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in segment A:  7\n",
      "Number of tokens in segment B:  347\n"
     ]
    }
   ],
   "source": [
    "#number of tokens in segment A (question) - this will be one more than the sep_idx as the index in Python starts from 0\n",
    "num_seg_a = sep_idx+1\n",
    "print(\"Number of tokens in segment A: \", num_seg_a)\n",
    "#number of tokens in segment B (text)\n",
    "num_seg_b = len(input_ids) - num_seg_a\n",
    "print(\"Number of tokens in segment B: \", num_seg_b)\n",
    "#creating the segment ids\n",
    "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "#making sure that every input token has a segment id\n",
    "assert len(segment_ids) == len(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s now feed this to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token input_ids to represent the input and token segment_ids to differentiate our segments - question and text\n",
    "output = model(torch.tensor([input_ids]),  token_type_ids=torch.tensor([segment_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question:\n",
      "Where did she pass?\n",
      "\n",
      "Answer:\n",
      "New york nursing home.\n"
     ]
    }
   ],
   "source": [
    "#tokens with highest start and end scores\n",
    "answer_start = torch.argmax(output.start_logits)\n",
    "answer_end = torch.argmax(output.end_logits)\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = tokens[answer_start]\n",
    "for i in range(answer_start+1, answer_end+1):\n",
    "    if tokens[i][0:2] == \"##\":\n",
    "        answer += tokens[i][2:]\n",
    "    else:\n",
    "        answer += \" \" + tokens[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text as a pair\n",
    "    input_ids = tokenizer.encode(question, text)    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    #print(tokens)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "    #number of tokens in segment A (question)\n",
    "    num_seg_a = sep_idx+1\n",
    "    #number of tokens in segment B (text)\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s for segment embeddings\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "    print(\"\\nPredicted answer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star's famous rhinestone-studded glove from a 1983 performance -- were auctioned off Saturday, reaping a total $2 million. Profits from the auction at the Hard Rock Cafe in New York's Times Square crushed pre-sale expectations of only $120,000 in sales. The highly prized memorabilia, which included items spanning the many stages of Jackson's career, came from more than 30 fans, associates and family members, who contacted Julien's Auctions to sell their gifts and mementos of the singer. Jackson's flashy glove was the big-ticket item of the night, fetching $420,000 from a buyer in Hong Kong, China. Jackson wore the glove at a 1983 performance during \\\"Motown 25,\\\" an NBC special where he debuted his revolutionary moonwalk. Fellow Motown star Walter \\\"Clyde\\\" Orange of the Commodores, who also performed in the special 26 years ago, said he asked for Jackson's autograph at the time, but Jackson gave him the glove instead. \"The legacy that [Jackson] left behind is bigger than life for me,\\\" Orange said. \\\"I hope that through that glove people can see what he was trying to say in his music and what he said in his music.\\\" Orange said he plans to give a portion of the proceeds to charity. Hoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer's premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York (CNN) -- More than 80 Michael Jackson collectibles -- including the late pop star\\'s famous rhinestone-studded glove from a 1983 performance -- were auctioned off Saturday, reaping a total $2 million. Profits from the auction at the Hard Rock Cafe in New York\\'s Times Square crushed pre-sale expectations of only $120,000 in sales. The highly prized memorabilia, which included items spanning the many stages of Jackson\\'s career, came from more than 30 fans, associates and family members, who contacted Julien\\'s Auctions to sell their gifts and mementos of the singer. Jackson\\'s flashy glove was the big-ticket item of the night, fetching $420,000 from a buyer in Hong Kong, China. Jackson wore the glove at a 1983 performance during \"Motown 25,\" an NBC special where he debuted his revolutionary moonwalk. Fellow Motown star Walter \"Clyde\" Orange of the Commodores, who also performed in the special 26 years ago, said he asked for Jackson\\'s autograph at the time, but Jackson gave him the glove instead. \"The legacy that [Jackson] left behind is bigger than life for me,\" Orange said. \"I hope that through that glove people can see what he was trying to say in his music and what he said in his music.\" Orange said he plans to give a portion of the proceeds to charity. Hoffman Ma, who bought the glove on behalf of Ponte 16 Resort in Macau, paid a 25 percent buyer\\'s premium, which was tacked onto all final sales over $50,000. Winners of items less than $50,000 paid a 20 percent premium.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Where was the Auction held?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "Hard rock cafe in new york ' s times square\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all. In fact, our BERT model gave a more detailed response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''My house\n",
    "My family lives in a house.\n",
    "Our house is very nice.\n",
    "It has two bedrooms.\n",
    "We cook and eat in the kitchen.\n",
    "We watch TV in the living room.\n",
    "My favorite room is my bedroom.\n",
    "I like to read books and do my homework in my bedroom.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='My favorite room is?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "My bedroom\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='My family lives in..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "A house\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=' Our house has two'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "It has two bedrooms\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='We cook and eat in the'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "The kitchen\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='I like to ____________ and __________ in my bedroom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "Read books and do my homework in my bedroom\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='We watch TV in the'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted answer:\n",
      "The living room\n"
     ]
    }
   ],
   "source": [
    "question_answer(question, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
